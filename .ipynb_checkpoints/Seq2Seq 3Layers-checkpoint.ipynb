{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Goal\n",
    "\n",
    "We will attemp to convert English into Pig Latin.  We will use the Text8 data as a corpus of text.  The modeling will be done using a sequence of characters and the input sequence will be the sequence of characters for one word.  We will use the method described [here](https://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf) \n",
    "\n",
    "<img src=\"S2S.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "words = pickle.load(open('t8_words.p'))\n",
    "words_pl = pickle.load(open('t8_words_pl.p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('biennials', 'iennialsbay'), ('tripolitan', 'ipolitantray'), ('mdbg', 'mdbgay'), ('roadgear', 'oadgearray'), ('vang', 'angvay'), ('nunnery', 'unnerynay'), ('sowell', 'owellsay'), ('brownpride', 'ownpridebray'), ('vani', 'anivay'), ('woods', 'oodsway')]\n"
     ]
    }
   ],
   "source": [
    "print zip(words[:10],words_pl[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Create validation set\n",
    "\n",
    "Taken from [here](https://en.oxforddictionaries.com/explore/weird-and-wonderful-words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def lessT(x):\n",
    "    if x <= 10:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "uncommon = ['abaya','bardolatry','blatherski','couthy','deterge','eyewater','saudade',\n",
    "            'tokoloshe','wittol','vomitous','waitron']\n",
    "assert (not any([u in words for u in uncommon]))\n",
    "assert all(map(lessT,map(len,uncommon)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Padding inputs and outputs\n",
    "\n",
    "There is no good way to handle sequences of multiple lengths (see [here](https://www.tensorflow.org/tutorials/seq2seq)).  So we pad inputs and outputs to fixed lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 tripolitan\n"
     ]
    }
   ],
   "source": [
    "# find maximum length of input\n",
    "max_in = 0\n",
    "ind = 0\n",
    "for i,w in enumerate(words):\n",
    "    if len(w)> max_in:\n",
    "        max_in = len(w)\n",
    "        ind = i\n",
    "print max_in, words[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 altagraciaway\n"
     ]
    }
   ],
   "source": [
    "# find maximum length of input\n",
    "max_out = 0\n",
    "ind = 0\n",
    "for i,w in enumerate(words_pl):\n",
    "    if len(w)> max_out:\n",
    "        max_out = len(w)\n",
    "        ind = i\n",
    "print max_out, words_pl[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pad_char = '~'\n",
    "def pad_in(w):\n",
    "    while(len(w)<max_in):\n",
    "        w = pad_char+w\n",
    "    return w\n",
    "\n",
    "def pad_out(w):\n",
    "    while(len(w)<max_out):\n",
    "        w = w+pad_char\n",
    "    return w\n",
    "\n",
    "def un_pad(w):\n",
    "    return w.replace(pad_char,'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~biennials\n",
      "iennialsbay~~\n"
     ]
    }
   ],
   "source": [
    "print pad_in(words[0])\n",
    "print pad_out(words_pl[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Vectorize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "alphabet = string.ascii_lowercase+'~'\n",
    "alphabet_size = len(alphabet)+1 #need to add one for the end of sequence key\n",
    "\n",
    "#returns a unique integer for the letter\n",
    "def char2id(x):\n",
    "    return alphabet.find(x)\n",
    "\n",
    "#return a one hot encoded vector of the letter\n",
    "def one_hot(l):\n",
    "    r = np.zeros(alphabet_size)\n",
    "    r[char2id(l)] = 1.0\n",
    "    return r\n",
    "\n",
    "#return the letter of the one-hot encoded letter\n",
    "def un_one_hot(v):\n",
    "    ind = np.argmax(v)\n",
    "#     if ind >= alphabet_size-2:\n",
    "    if ind == alphabet_size-1:\n",
    "        return ''\n",
    "    else:\n",
    "        return alphabet[ind]\n",
    "\n",
    "#returns the the End of Sequence vector\n",
    "def getEOSvec():\n",
    "    r = np.zeros(alphabet_size)\n",
    "    r[alphabet_size-1] = 1.0\n",
    "    return r\n",
    "\n",
    "#returns the word a matrix of one hot encoded vectors\n",
    "def vectorizeWord(w):\n",
    "    r = np.ndarray((len(w)+1,alphabet_size))\n",
    "    for i,l in enumerate(w):\n",
    "        r[i] = one_hot(l)\n",
    "    r[len(w)] = getEOSvec()\n",
    "    return r\n",
    "\n",
    "#returns the string of the vectorized word\n",
    "def unvectorizeWord(M):\n",
    "    r = ''\n",
    "    for i in xrange(M.shape[0]):\n",
    "        r += un_one_hot(M[i])\n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Batch Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "batch_size=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Batch(object):\n",
    "    def __init__(self,words,words_pl,batch_size):\n",
    "        self.words = words\n",
    "        self.words_pl = words_pl\n",
    "        self.batch_size = batch_size\n",
    "        self.size = len(words)\n",
    "        self.segment_size = self.size/batch_size\n",
    "        self.cursors = [b*self.segment_size for b in range(batch_size)]\n",
    "        #self.batch = np.ndarray(self.batch_size)\n",
    "    def nextBatch(self,reverse = True):\n",
    "        if reverse:\n",
    "            x = np.array([vectorizeWord(pad_in(words[c][::-1])) for c in self.cursors])\n",
    "        else:\n",
    "            x = np.array([vectorizeWord(pad_in(words[c])) for c in self.cursors])\n",
    "        y = np.array([vectorizeWord(pad_out(words_pl[c])) for c in self.cursors])\n",
    "        self.cursors = [(c+1)%self.size for c in self.cursors]\n",
    "        return x,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Deep LSTM\n",
    "\n",
    "https://arxiv.org/pdf/1409.2329.pdf\n",
    "\n",
    "<img src=\"OtherLSTM.png\">  <img src=\"stacked_LSTM.png\", width = \"25%\", height = \"25%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-14-2efc55b253d8>:118 in <module>.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "#NOTE: the +1 in max_in+1 and max_out+1 happens because the end token is needed\n",
    "\n",
    "num_nodes = 500\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    #input sequence\n",
    "    input_sequence = list()\n",
    "    for i in range(max_in+1):\n",
    "        input_sequence.append(tf.placeholder(tf.float32,shape=(batch_size,alphabet_size)))\n",
    "    \n",
    "    #target sequence\n",
    "    target_sequence = list()\n",
    "    for i in range(max_out+1):\n",
    "        target_sequence.append(tf.placeholder(tf.float32,shape=(batch_size,alphabet_size)))\n",
    "        \n",
    "    \n",
    "    #the previous state that gets fed into the cell\n",
    "    state_0 = tf.constant(0.0,dtype=tf.float32,shape=[batch_size,num_nodes])\n",
    "    hidden_0 = tf.constant(0.0,dtype=tf.float32,shape=[batch_size,num_nodes])\n",
    "    #for validation inference\n",
    "    state_0v = tf.constant(0.0,dtype=tf.float32,shape=[1,num_nodes])\n",
    "    hidden_0v = tf.constant(0.0,dtype=tf.float32,shape=[1,num_nodes])\n",
    "    \n",
    "    def create_LSTM_Variables(num_nodes,Name,is_input=False):\n",
    "        if is_input:\n",
    "            fx = tf.Variable(tf.truncated_normal([num_nodes+alphabet_size, num_nodes], -0.08, 0.08),name=Name+'fx')\n",
    "            ix = tf.Variable(tf.truncated_normal([num_nodes+alphabet_size, num_nodes], -0.08, 0.08),name=Name+'ix')\n",
    "            cx = tf.Variable(tf.truncated_normal([num_nodes+alphabet_size, num_nodes], -0.08, 0.08),name=Name+'cx')\n",
    "            ox = tf.Variable(tf.truncated_normal([num_nodes+alphabet_size, num_nodes], -0.08, 0.08),name=Name+'ox')\n",
    "        else:\n",
    "            fx = tf.Variable(tf.truncated_normal([2*num_nodes, num_nodes], -0.08, 0.08),name=Name+'fx')\n",
    "            ix = tf.Variable(tf.truncated_normal([2*num_nodes, num_nodes], -0.08, 0.08),name=Name+'ix')\n",
    "            cx = tf.Variable(tf.truncated_normal([2*num_nodes, num_nodes], -0.08, 0.08),name=Name+'cx')\n",
    "            ox = tf.Variable(tf.truncated_normal([2*num_nodes, num_nodes], -0.08, 0.08),name=Name+'ox')\n",
    "        fb = tf.Variable(tf.zeros([1, num_nodes]),name=Name+'fb')\n",
    "        ib = tf.Variable(tf.zeros([1, num_nodes]),name=Name+'ib')\n",
    "        cb = tf.Variable(tf.zeros([1, num_nodes]),name=Name+'cb')\n",
    "        ob = tf.Variable(tf.zeros([1, num_nodes]),name=Name+'ob')\n",
    "        return[[fx,ix,cx,ox],[fb,ib,cb,ob]]\n",
    "    \n",
    "    e1_var = create_LSTM_Variables(num_nodes,'e1',is_input = True)\n",
    "    e2_var = create_LSTM_Variables(num_nodes,'e2')\n",
    "    e3_var = create_LSTM_Variables(num_nodes,'e3')\n",
    "    \n",
    "    d1_var = create_LSTM_Variables(num_nodes,'d1',is_input = True)\n",
    "    d2_var = create_LSTM_Variables(num_nodes,'d2')\n",
    "    d3_var = create_LSTM_Variables(num_nodes,'d3')\n",
    "    \n",
    "    #softmax\n",
    "    W_softmax = tf.Variable(tf.truncated_normal([num_nodes,alphabet_size],-0.08,0.08))\n",
    "    b_softmax = tf.Variable(tf.zeros([1,alphabet_size]))\n",
    "    \n",
    "    #model\n",
    "    #hl is the previous hiddent layer from current time step but previous  layer\n",
    "    #ht is the previous hidden layer from the current layer but previous timestep\n",
    "    #state is the previous state from the same layer but previous timestep\n",
    "    def LSTM(hl,ht,state,varrs):\n",
    "        #get variables out\n",
    "        x,b=varrs[0],varrs[1]\n",
    "        fx,ix,cx,ox = x[0],x[1],x[2],x[3]\n",
    "        fb,ib,cb,ob = b[0],b[1],b[1],b[3]\n",
    "        \n",
    "        #computations\n",
    "        input_chan = tf.concat(1,[hl,ht])\n",
    "        forget_gate = tf.sigmoid(tf.matmul(input_chan,fx)+fb)\n",
    "        insert_gate = tf.sigmoid(tf.matmul(input_chan,ix)+ib)\n",
    "        output_gate = tf.sigmoid(tf.matmul(input_chan,ox)+ob)\n",
    "        candidate = tf.tanh(tf.matmul(input_chan,cx)+cb)\n",
    "        state = forget_gate * state + insert_gate * candidate\n",
    "        h = output_gate * tf.tanh(state)\n",
    "        return h, state\n",
    "    \n",
    "    \n",
    "    def model(input_sequence,train = True):\n",
    "        #Encode sequence\n",
    "        for i in range(max_in+1):\n",
    "            if i == 0:\n",
    "                if train:\n",
    "                    state1,h1 = state_0,hidden_0\n",
    "                    state2,h2 = state_0,hidden_0\n",
    "                    state3,h3 = state_0,hidden_0\n",
    "                else:\n",
    "                    state1,h1 = state_0v,hidden_0v\n",
    "                    state2,h2 = state_0v,hidden_0v\n",
    "                    state3,h3 = state_0v,hidden_0v\n",
    "\n",
    "            h1,state1 = LSTM(h1,input_sequence[i],state1,e1_var) #layer 1\n",
    "            h2,state2 = LSTM(h2,h1,state2,e2_var) #layer 2\n",
    "            h3,state3 = LSTM(h3,h2,state3,e3_var) #layer 3\n",
    "\n",
    "        #Decode sequence\n",
    "        logits_list = list()\n",
    "        for i in range(max_out+1):\n",
    "            if i == 0:\n",
    "                h1,state1 = LSTM(h1,input_sequence[-1],state1,d1_var) #layer 1\n",
    "\n",
    "            else:\n",
    "                h1,state1 = LSTM(h1,tf.nn.softmax(logit),state1,d1_var) #layer 1\n",
    "            h2,state2 = LSTM(h2,h1,state2,d2_var) #layer 2\n",
    "            h3,state3 = LSTM(h3,h2,state3,d3_var) #layer 3\n",
    "\n",
    "            logit =tf.matmul(h3,W_softmax)+b_softmax\n",
    "            logits_list.append(logit)\n",
    "\n",
    "        logits = tf.concat(0,logits_list)\n",
    "        return logits\n",
    "    \n",
    "    #train\n",
    "    logits_train = model(input_sequence)\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits_train,labels=tf.concat(0,target_sequence)))\n",
    "    opt = tf.train.AdamOptimizer(learning_rate=1e-3).minimize(loss)\n",
    "    \n",
    "    #inference train\n",
    "    pred = tf.nn.softmax(logits_train)\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "        \n",
    "    init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session(graph = g)\n",
    "sess.run(init)\n",
    "b = Batch(words,words_pl,batch_size)\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# saver.restore(sess,os.getcwd()+'/model3.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7142"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch_steps = b.segment_size\n",
    "epoch_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/5001 [00:00<10:54,  7.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.0620775\n",
      "Input:           unmanifest\n",
      "Output:          unmanifectway\n",
      "Correct Output:  unmanifestway\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 103/5001 [00:08<07:07, 11.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.0256837\n",
      "Input:           equivocal~\n",
      "Output:          equivocalway~\n",
      "Correct Output:  equivocalway~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 203/5001 [00:17<07:33, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.0449511\n",
      "Input:           quilty~~~~\n",
      "Output:          uiltyqay~~~~~\n",
      "Correct Output:  uiltyqay~~~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 303/5001 [00:25<06:48, 11.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.0261725\n",
      "Input:           gelon~~~~~\n",
      "Output:          elongay~~~~~~\n",
      "Correct Output:  elongay~~~~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 403/5001 [00:34<06:42, 11.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.131156\n",
      "Input:           punters~~~\n",
      "Output:          unterspay~~~~\n",
      "Correct Output:  unterspay~~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 503/5001 [00:42<06:38, 11.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.0233885\n",
      "Input:           nicoud~~~~\n",
      "Output:          icoudnay~~~~~\n",
      "Correct Output:  icoudnay~~~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 603/5001 [00:51<06:31, 11.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.0414006\n",
      "Input:           ardilaun~~\n",
      "Output:          ardilaunway~~\n",
      "Correct Output:  ardilaunway~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 703/5001 [00:59<06:18, 11.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.0129006\n",
      "Input:           sheng~~~~~\n",
      "Output:          engshay~~~~~~\n",
      "Correct Output:  engshay~~~~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 803/5001 [01:07<06:08, 11.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.0162584\n",
      "Input:           athem~~~~~\n",
      "Output:          athemway~~~~~\n",
      "Correct Output:  athemway~~~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 903/5001 [01:16<05:59, 11.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.0574528\n",
      "Input:           hdmi~~~~~~\n",
      "Output:          ihmmay~~~~~~~\n",
      "Correct Output:  ihdmay~~~~~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1003/5001 [01:24<05:48, 11.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.0236404\n",
      "Input:           sotkanet~~\n",
      "Output:          otkanetsay~~~\n",
      "Correct Output:  otkanetsay~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 1103/5001 [01:32<05:44, 11.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.0461024\n",
      "Input:           mntv~~~~~~\n",
      "Output:          mntvay~~~~~~~\n",
      "Correct Output:  mntvay~~~~~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 1203/5001 [01:41<05:33, 11.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.0164254\n",
      "Input:           deerfoot~~\n",
      "Output:          eerfootday~~~\n",
      "Correct Output:  eerfootday~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 1303/5001 [01:49<05:23, 11.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.0280573\n",
      "Input:           wagers~~~~\n",
      "Output:          agersway~~~~~\n",
      "Correct Output:  agersway~~~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 1403/5001 [01:58<05:20, 11.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.0859764\n",
      "Input:           vojt~~~~~~\n",
      "Output:          ojtvay~~~~~~~\n",
      "Correct Output:  ojtvay~~~~~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 1503/5001 [02:06<05:02, 11.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.0266604\n",
      "Input:           mined~~~~~\n",
      "Output:          inedmay~~~~~~\n",
      "Correct Output:  inedmay~~~~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 1603/5001 [02:14<05:00, 11.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.017252\n",
      "Input:           broadbeach\n",
      "Output:          oadbeachbray~\n",
      "Correct Output:  oadbeachbray~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 1703/5001 [02:23<04:44, 11.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.0561533\n",
      "Input:           atea~~~~~~\n",
      "Output:          ateaway~~~~~~\n",
      "Correct Output:  ateaway~~~~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 1803/5001 [02:31<04:39, 11.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.0316903\n",
      "Input:           tamassia~~\n",
      "Output:          amassiatay~~~\n",
      "Correct Output:  amassiatay~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 1903/5001 [02:40<04:29, 11.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.0291154\n",
      "Input:           kitabu~~~~\n",
      "Output:          itabukay~~~~~\n",
      "Correct Output:  itabukay~~~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2003/5001 [02:48<04:20, 11.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.0126829\n",
      "Input:           chanceless\n",
      "Output:          ancelesschay~\n",
      "Correct Output:  ancelesschay~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 2103/5001 [02:57<04:13, 11.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.042716\n",
      "Input:           cockle~~~~\n",
      "Output:          ocklecay~~~~~\n",
      "Correct Output:  ocklecay~~~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 2203/5001 [03:05<04:06, 11.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.0152698\n",
      "Input:           cnida~~~~~\n",
      "Output:          idacnay~~~~~~\n",
      "Correct Output:  idacnay~~~~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 2303/5001 [03:13<03:56, 11.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.0374374\n",
      "Input:           orlandini~\n",
      "Output:          orlandiniway~\n",
      "Correct Output:  orlandiniway~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 2403/5001 [03:22<03:49, 11.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.0419032\n",
      "Input:           textbook~~\n",
      "Output:          extbooktay~~~\n",
      "Correct Output:  extbooktay~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2503/5001 [03:30<03:37, 11.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.0204889\n",
      "Input:           caldmore~~\n",
      "Output:          aldmorecay~~~\n",
      "Correct Output:  aldmorecay~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 2603/5001 [03:38<03:32, 11.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.019139\n",
      "Input:           indepently\n",
      "Output:          indepentlyway\n",
      "Correct Output:  indepentlyway\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 2703/5001 [03:47<03:18, 11.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.059061\n",
      "Input:           nanini~~~~\n",
      "Output:          anininay~~~~~\n",
      "Correct Output:  anininay~~~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 2803/5001 [03:55<03:14, 11.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.0334718\n",
      "Input:           okhas~~~~~\n",
      "Output:          okhasway~~~~~\n",
      "Correct Output:  okhasway~~~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 2903/5001 [04:04<03:04, 11.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.00730868\n",
      "Input:           boudiga~~~\n",
      "Output:          oudigabay~~~~\n",
      "Correct Output:  oudigabay~~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3003/5001 [04:12<02:54, 11.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.0147266\n",
      "Input:           tribal~~~~\n",
      "Output:          ibaltray~~~~~\n",
      "Correct Output:  ibaltray~~~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 3103/5001 [04:20<02:46, 11.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.0145968\n",
      "Input:           cherbury~~\n",
      "Output:          erburychay~~~\n",
      "Correct Output:  erburychay~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 3203/5001 [04:29<02:34, 11.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.0585774\n",
      "Input:           castellu~~\n",
      "Output:          astellucay~~~\n",
      "Correct Output:  astellucay~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 3303/5001 [04:37<02:28, 11.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.0704653\n",
      "Input:           mandala~~~\n",
      "Output:          andalamay~~~~\n",
      "Correct Output:  andalamay~~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 3403/5001 [04:46<02:20, 11.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.006235\n",
      "Input:           paperclick\n",
      "Output:          aperclickpay~\n",
      "Correct Output:  aperclickpay~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 3503/5001 [04:54<02:11, 11.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.0304102\n",
      "Input:           camote~~~~\n",
      "Output:          amotecay~~~~~\n",
      "Correct Output:  amotecay~~~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 3603/5001 [05:02<02:01, 11.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.0355545\n",
      "Input:           ingerman~~\n",
      "Output:          ingermanway~~\n",
      "Correct Output:  ingermanway~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 3703/5001 [05:11<01:53, 11.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.0134291\n",
      "Input:           comand~~~~\n",
      "Output:          omandcay~~~~~\n",
      "Correct Output:  omandcay~~~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 3803/5001 [05:19<01:43, 11.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.0154765\n",
      "Input:           rosett~~~~\n",
      "Output:          osettray~~~~~\n",
      "Correct Output:  osettray~~~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 3903/5001 [05:28<01:35, 11.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.00550721\n",
      "Input:           quammen~~~\n",
      "Output:          uammenqay~~~~\n",
      "Correct Output:  uammenqay~~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4003/5001 [05:36<01:26, 11.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.00845804\n",
      "Input:           daugther~~\n",
      "Output:          augtherday~~~\n",
      "Correct Output:  augtherday~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 4103/5001 [05:44<01:18, 11.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.011697\n",
      "Input:           taiaha~~~~\n",
      "Output:          aiahatay~~~~~\n",
      "Correct Output:  aiahatay~~~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 4203/5001 [05:53<01:10, 11.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.0347584\n",
      "Input:           nissa~~~~~\n",
      "Output:          issanay~~~~~~\n",
      "Correct Output:  issanay~~~~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 4303/5001 [06:01<01:00, 11.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.0109279\n",
      "Input:           antelope~~\n",
      "Output:          antelopeway~~\n",
      "Correct Output:  antelopeway~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 4403/5001 [06:10<00:52, 11.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.054379\n",
      "Input:           qualifying\n",
      "Output:          ualifyingqay~\n",
      "Correct Output:  ualifyingqay~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 4503/5001 [06:18<00:43, 11.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.0320379\n",
      "Input:           mechanical\n",
      "Output:          echanicalmay~\n",
      "Correct Output:  echanicalmay~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 4603/5001 [06:26<00:35, 11.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.0284221\n",
      "Input:           endf~~~~~~\n",
      "Output:          endfway~~~~~~\n",
      "Correct Output:  endfway~~~~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 4703/5001 [06:35<00:25, 11.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.00930039\n",
      "Input:           sheck~~~~~\n",
      "Output:          eckshay~~~~~~\n",
      "Correct Output:  eckshay~~~~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 4803/5001 [06:43<00:17, 11.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.010853\n",
      "Input:           hatorah~~~\n",
      "Output:          atorahhay~~~~\n",
      "Correct Output:  atorahhay~~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 4903/5001 [06:52<00:08, 11.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.0259013\n",
      "Input:           boldirev~~\n",
      "Output:          oldirevbay~~~\n",
      "Correct Output:  oldirevbay~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5001/5001 [07:00<00:00, 11.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.0376123\n",
      "Input:           terbock~~~\n",
      "Output:          erbocktay~~~~\n",
      "Correct Output:  erbocktay~~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_steps = 5001\n",
    "for s in tqdm(range(num_steps)):\n",
    "    fd = {}\n",
    "    x,y = b.nextBatch(reverse=True)\n",
    "    for i in range(len(x[0,:,0])):\n",
    "        fd[input_sequence[i]] = x[:,i,:]\n",
    "    for i in range(len(y[0,:,0])):\n",
    "        fd[target_sequence[i]] = y[:,i,:]\n",
    "    \n",
    "    l,_ = sess.run([loss,opt],feed_dict = fd)\n",
    "    losses.append(l)\n",
    "    if s % 100 == 0:\n",
    "        translated = sess.run([pred],feed_dict=fd)[0]\n",
    "        #onlt check the first word\n",
    "        fw_o = np.ndarray((max_out,alphabet_size))\n",
    "        for i in range(max_out):\n",
    "            fw_o[i]=translated[i*batch_size]\n",
    "    \n",
    "        print 'loss: ',l\n",
    "        print 'Input:          ',unvectorizeWord(x[0])[::-1]\n",
    "        print 'Output:         ',unvectorizeWord(fw_o)\n",
    "        print 'Correct Output: ',unvectorizeWord(y[0])\n",
    "        print ' '\n",
    "save_path = saver.save(sess,os.getcwd()+'/model3.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f277c681ad0>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAFkCAYAAAB8RXKEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n10aiAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f28748045d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with g.as_default():\n",
    "    val_sequence = list()\n",
    "    for i in range(max_in+1):\n",
    "        val_sequence.append(tf.placeholder(tf.float32,shape=(1,alphabet_size)))\n",
    "    logits_val = model(val_sequence,train=False)\n",
    "    pred_val = tf.nn.softmax(logits_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:           abaya\n",
      "Output:          abayaway~~~~~\n",
      " \n",
      "Input:           bardolatry\n",
      "Output:          ardolatrybay~\n",
      " \n",
      "Input:           blatherski\n",
      "Output:          atherskiblay~\n",
      " \n",
      "Input:           couthy\n",
      "Output:          outhycay~~~~~\n",
      " \n",
      "Input:           deterge\n",
      "Output:          etergeday~~~~\n",
      " \n",
      "Input:           eyewater\n",
      "Output:          eyewaterway~~\n",
      " \n",
      "Input:           saudade\n",
      "Output:          audadesay~~~~\n",
      " \n",
      "Input:           tokoloshe\n",
      "Output:          okoloshetay~~\n",
      " \n",
      "Input:           wittol\n",
      "Output:          ittolway~~~~~\n",
      " \n",
      "Input:           vomitous\n",
      "Output:          omitousvay~~~\n",
      " \n",
      "Input:           waitron\n",
      "Output:          aitronway~~~~\n",
      " \n"
     ]
    }
   ],
   "source": [
    "#validation\n",
    "for s in range(len(uncommon)):\n",
    "    inputs = vectorizeWord(pad_in(uncommon[s][::-1]))\n",
    "    \n",
    "    fd = {}\n",
    "    for i in range(len(inputs)):\n",
    "        fd[val_sequence[i]] = np.expand_dims(inputs[i],0)\n",
    "    \n",
    "    translated = sess.run([pred_val],feed_dict=fd)[0]\n",
    "    print 'Input:          ',uncommon[s]\n",
    "    print 'Output:         ',unvectorizeWord(translated)\n",
    "    print ' '"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Get Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_params = sess.run([e1_var,e2_var,e3_var,d1_var,d2_var,d3_var,W_softmax,b_softmax])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle.dump(model_params,open('params.p','w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
