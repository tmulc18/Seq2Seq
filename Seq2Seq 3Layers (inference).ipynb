{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Goal\n",
    "\n",
    "We will attemp to convert English into Pig Latin.  We will use the Text8 data as a corpus of text.  The modeling will be done using a sequence of characters and the input sequence will be the sequence of characters for one word.  We will use the method described [here](https://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import parameters\n",
    "\n",
    "[e1_var,e2_var,e3_var,d1_var,d2_var,d3_var,W_softmax,b_softmax]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = pickle.load(open('params.p','r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Padding inputs and outputs\n",
    "\n",
    "There is no good way to handle sequences of multiple lengths (see [here](https://www.tensorflow.org/tutorials/seq2seq)).  So we pad inputs and outputs to fixed lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# find maximum length of input\n",
    "max_in = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# find maximum length of input\n",
    "max_out = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pad_char = '~'\n",
    "def pad_in(w):\n",
    "    while(len(w)<max_in):\n",
    "        w = pad_char+w\n",
    "    return w\n",
    "\n",
    "def pad_out(w):\n",
    "    while(len(w)<max_out):\n",
    "        w = w+pad_char\n",
    "    return w\n",
    "\n",
    "def un_pad(w):\n",
    "    return w.replace(pad_char,'')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Vectorize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "alphabet = string.ascii_lowercase+'~'\n",
    "alphabet_size = len(alphabet)+1 #need to add one for the end of sequence key\n",
    "\n",
    "#returns a unique integer for the letter\n",
    "def char2id(x):\n",
    "    return alphabet.find(x)\n",
    "\n",
    "#return a one hot encoded vector of the letter\n",
    "def one_hot(l):\n",
    "    r = np.zeros(alphabet_size)\n",
    "    r[char2id(l)] = 1.0\n",
    "    return r\n",
    "\n",
    "#return the letter of the one-hot encoded letter\n",
    "def un_one_hot(v):\n",
    "    ind = np.argmax(v)\n",
    "#     if ind >= alphabet_size-2:\n",
    "    if ind == alphabet_size-1:\n",
    "        return ''\n",
    "    else:\n",
    "        return alphabet[ind]\n",
    "\n",
    "#returns the the End of Sequence vector\n",
    "def getEOSvec():\n",
    "    r = np.zeros(alphabet_size)\n",
    "    r[alphabet_size-1] = 1.0\n",
    "    return r\n",
    "\n",
    "#returns the word a matrix of one hot encoded vectors\n",
    "def vectorizeWord(w):\n",
    "    r = np.ndarray((len(w)+1,alphabet_size))\n",
    "    for i,l in enumerate(w):\n",
    "        r[i] = one_hot(l)\n",
    "    r[len(w)] = getEOSvec()\n",
    "    return r\n",
    "\n",
    "#returns the string of the vectorized word\n",
    "def unvectorizeWord(M):\n",
    "    r = ''\n",
    "    for i in xrange(M.shape[0]):\n",
    "        r += un_one_hot(M[i])\n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Deep Traditional\n",
    "\n",
    "https://arxiv.org/pdf/1409.2329.pdf\n",
    "\n",
    "<img src=\"Notes/OtherLSTM.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#NOTE: the +1 in max_in+1 and max_out+1 happens because the end token is needed\n",
    "\n",
    "num_nodes = 500\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    #the previous state that gets fed into the cell\n",
    "    state_0v = tf.constant(0.0,dtype=tf.float32,shape=[1,num_nodes])\n",
    "    hidden_0v = tf.constant(0.0,dtype=tf.float32,shape=[1,num_nodes])\n",
    "    \n",
    "    def create_LSTM_Variables(num_nodes,iv,Name,is_input=False):\n",
    "        if is_input:\n",
    "            fx = tf.Variable(iv[0][0],name=Name+'fx')\n",
    "            ix = tf.Variable(iv[0][1],name=Name+'ix')\n",
    "            cx = tf.Variable(iv[0][2],name=Name+'cx')\n",
    "            ox = tf.Variable(iv[0][3],name=Name+'ox')\n",
    "        else:\n",
    "            fx = tf.Variable(iv[0][0],name=Name+'fx')\n",
    "            ix = tf.Variable(iv[0][1],name=Name+'ix')\n",
    "            cx = tf.Variable(iv[0][2],name=Name+'cx')\n",
    "            ox = tf.Variable(iv[0][3],name=Name+'ox')\n",
    "        fb = tf.Variable(iv[1][0],name=Name+'fb')\n",
    "        ib = tf.Variable(iv[1][1],name=Name+'ib')\n",
    "        cb = tf.Variable(iv[1][2],name=Name+'cb')\n",
    "        ob = tf.Variable(iv[1][3],name=Name+'ob')\n",
    "        return[[fx,ix,cx,ox],[fb,ib,cb,ob]]\n",
    "    \n",
    "    e1_var = create_LSTM_Variables(num_nodes,params[0],'e1',is_input = True)\n",
    "    e2_var = create_LSTM_Variables(num_nodes,params[1],'e2')\n",
    "    e3_var = create_LSTM_Variables(num_nodes,params[2],'e3')\n",
    "    \n",
    "    d1_var = create_LSTM_Variables(num_nodes,params[3],'d1',is_input = True)\n",
    "    d2_var = create_LSTM_Variables(num_nodes,params[4],'d2')\n",
    "    d3_var = create_LSTM_Variables(num_nodes,params[5],'d3')\n",
    "    \n",
    "    #softmax\n",
    "    W_softmax = tf.Variable(params[6])\n",
    "    b_softmax = tf.Variable(params[7])\n",
    "    \n",
    "    #model\n",
    "    #hl is the previous hiddent layer from current time step but previous  layer\n",
    "    #ht is the previous hidden layer from the current layer but previous timestep\n",
    "    #state is the previous state from the same layer but previous timestep\n",
    "    def LSTM(hl,ht,state,varrs):\n",
    "        #get variables out\n",
    "        x,b=varrs[0],varrs[1]\n",
    "        fx,ix,cx,ox = x[0],x[1],x[2],x[3]\n",
    "        fb,ib,cb,ob = b[0],b[1],b[1],b[3]\n",
    "        \n",
    "        #computations\n",
    "        input_chan = tf.concat(1,[hl,ht])\n",
    "        forget_gate = tf.sigmoid(tf.matmul(input_chan,fx)+fb)\n",
    "        insert_gate = tf.sigmoid(tf.matmul(input_chan,ix)+ib)\n",
    "        output_gate = tf.sigmoid(tf.matmul(input_chan,ox)+ob)\n",
    "        candidate = tf.tanh(tf.matmul(input_chan,cx)+cb)\n",
    "        state = forget_gate * state + insert_gate * candidate\n",
    "        h = output_gate * tf.tanh(state)\n",
    "        return h, state\n",
    "    \n",
    "    \n",
    "    def model(input_sequence,train = True):\n",
    "        #Encode sequence\n",
    "        for i in range(max_in+1):\n",
    "            if i == 0:\n",
    "                if train:\n",
    "                    state1,h1 = state_0,hidden_0\n",
    "                    state2,h2 = state_0,hidden_0\n",
    "                    state3,h3 = state_0,hidden_0\n",
    "                else:\n",
    "                    state1,h1 = state_0v,hidden_0v\n",
    "                    state2,h2 = state_0v,hidden_0v\n",
    "                    state3,h3 = state_0v,hidden_0v\n",
    "\n",
    "            h1,state1 = LSTM(h1,input_sequence[i],state1,e1_var) #layer 1\n",
    "            h2,state2 = LSTM(h2,h1,state2,e2_var) #layer 2\n",
    "            h3,state3 = LSTM(h3,h2,state3,e3_var) #layer 3\n",
    "\n",
    "        #Decode sequence\n",
    "        logits_list = list()\n",
    "        for i in range(max_out+1):\n",
    "            if i == 0:\n",
    "                h1,state1 = LSTM(h1,input_sequence[-1],state1,d1_var) #layer 1\n",
    "\n",
    "            else:\n",
    "                h1,state1 = LSTM(h1,tf.nn.softmax(logit),state1,d1_var) #layer 1\n",
    "            h2,state2 = LSTM(h2,h1,state2,d2_var) #layer 2\n",
    "            h3,state3 = LSTM(h3,h2,state3,d3_var) #layer 3\n",
    "\n",
    "            logit =tf.matmul(h3,W_softmax)+b_softmax\n",
    "            logits_list.append(logit)\n",
    "\n",
    "        logits = tf.concat(0,logits_list)\n",
    "        return logits\n",
    "    \n",
    "    #inference train\n",
    "#     pred = tf.nn.softmax(logits_train)\n",
    "        \n",
    "    init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session(graph = g)\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with g.as_default():\n",
    "    val_sequence = list()\n",
    "    for i in range(max_in+1):\n",
    "        val_sequence.append(tf.placeholder(tf.float32,shape=(1,alphabet_size)))\n",
    "    logits_val = model(val_sequence,train=False)\n",
    "    pred_val = tf.nn.softmax(logits_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:           piglatin\n",
      "Output:          iglatinpay~~~\n",
      " \n",
      "Input:           translator\n",
      "Output:          anslaturtray~\n",
      " \n",
      "Input:           is\n",
      "Output:          isway~~~~~~~~\n",
      " \n",
      "Input:           working\n",
      "Output:          orkingway~~~~\n",
      " \n"
     ]
    }
   ],
   "source": [
    "v = ['piglatin','translator','is','working']\n",
    "for s in range(len(v)):\n",
    "    inputs = vectorizeWord(pad_in(v[s][::-1]))\n",
    "    \n",
    "    fd = {}\n",
    "    for i in range(len(inputs)):\n",
    "        fd[val_sequence[i]] = np.expand_dims(inputs[i],0)\n",
    "    \n",
    "    translated = sess.run([pred_val],feed_dict=fd)[0]\n",
    "    print 'Input:          ',v[s]\n",
    "    print 'Output:         ',unvectorizeWord(translated)\n",
    "    print ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
