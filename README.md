# Seq2Seq
Create a sequence to sequence model that translate English words into pig Latin 

## Download parameters

https://drive.google.com/open?id=0B3NC6C-8OM5BaV9vRUpjcl9WZmc

## How to use

Seq2Seq 3Layers.ipynb is used to train the encoder and decoder

Seq2Seq 3Layers (inference).ipynb will use the parameters stored in params.p to run inference on a given input sequence

## Implementation details

Followed the famous Sequence to Sequence paper but this implemenation was only 3 LSTM cells deep each with only 500 nodes 
