{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal\n",
    "\n",
    "We will attemp to convert English into Pig Latin.  We will use the Text8 data as a corpus of text.  The modeling will be done using a sequence of characters and the input sequence will be the sequence of characters for one word.  We will use the method described [here](https://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf) \n",
    "\n",
    "<img src=\"S2S.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention: https://arxiv.org/pdf/1412.7449.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = pickle.load(open('t8_words.p'))\n",
    "words_pl = pickle.load(open('t8_words_pl.p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('biennials', 'iennialsbay'), ('tripolitan', 'ipolitantray'), ('mdbg', 'mdbgay'), ('roadgear', 'oadgearray'), ('vang', 'angvay'), ('nunnery', 'unnerynay'), ('sowell', 'owellsay'), ('brownpride', 'ownpridebray'), ('vani', 'anivay'), ('woods', 'oodsway')]\n"
     ]
    }
   ],
   "source": [
    "print zip(words[:10],words_pl[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create validation set\n",
    "\n",
    "Taken from [here](https://en.oxforddictionaries.com/explore/weird-and-wonderful-words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lessT(x):\n",
    "    if x <= 10:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uncommon = ['abaya','bardolatry','blatherski','couthy','deterge','eyewater','saudade',\n",
    "            'tokoloshe','wittol','vomitous','waitron']\n",
    "assert (not any([u in words for u in uncommon]))\n",
    "assert all(map(lessT,map(len,uncommon)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Padding inputs and outputs\n",
    "\n",
    "There is no good way to handle sequences of multiple lengths (see [here](https://www.tensorflow.org/tutorials/seq2seq)).  So we pad inputs and outputs to fixed lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 tripolitan\n"
     ]
    }
   ],
   "source": [
    "# find maximum length of input\n",
    "max_in = 0\n",
    "ind = 0\n",
    "for i,w in enumerate(words):\n",
    "    if len(w)> max_in:\n",
    "        max_in = len(w)\n",
    "        ind = i\n",
    "print max_in, words[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 altagraciaway\n"
     ]
    }
   ],
   "source": [
    "# find maximum length of input\n",
    "max_out = 0\n",
    "ind = 0\n",
    "for i,w in enumerate(words_pl):\n",
    "    if len(w)> max_out:\n",
    "        max_out = len(w)\n",
    "        ind = i\n",
    "print max_out, words_pl[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pad_char = '~'\n",
    "def pad_in(w):\n",
    "    while(len(w)<max_in):\n",
    "        w = pad_char+w\n",
    "    return w\n",
    "\n",
    "def pad_out(w):\n",
    "    while(len(w)<max_out):\n",
    "        w = w+pad_char\n",
    "    return w\n",
    "\n",
    "def un_pad(w):\n",
    "    return w.replace(pad_char,'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~biennials\n",
      "iennialsbay~~\n"
     ]
    }
   ],
   "source": [
    "print pad_in(words[0])\n",
    "print pad_out(words_pl[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alphabet = string.ascii_lowercase+'~'\n",
    "alphabet_size = len(alphabet)+1 #need to add one for the end of sequence key\n",
    "\n",
    "#returns a unique integer for the letter\n",
    "def char2id(x):\n",
    "    return alphabet.find(x)\n",
    "\n",
    "#return a one hot encoded vector of the letter\n",
    "def one_hot(l):\n",
    "    r = np.zeros(alphabet_size)\n",
    "    r[char2id(l)] = 1.0\n",
    "    return r\n",
    "\n",
    "#return the letter of the one-hot encoded letter\n",
    "def un_one_hot(v):\n",
    "    ind = np.argmax(v)\n",
    "#     if ind >= alphabet_size-2:\n",
    "    if ind == alphabet_size-1:\n",
    "        return ''\n",
    "    else:\n",
    "        return alphabet[ind]\n",
    "\n",
    "#returns the the End of Sequence vector\n",
    "def getEOSvec():\n",
    "    r = np.zeros(alphabet_size)\n",
    "    r[alphabet_size-1] = 1.0\n",
    "    return r\n",
    "\n",
    "#returns the word a matrix of one hot encoded vectors\n",
    "def vectorizeWord(w):\n",
    "    r = np.ndarray((len(w)+1,alphabet_size))\n",
    "    for i,l in enumerate(w):\n",
    "        r[i] = one_hot(l)\n",
    "    r[len(w)] = getEOSvec()\n",
    "    return r\n",
    "\n",
    "#returns the string of the vectorized word\n",
    "def unvectorizeWord(M):\n",
    "    r = ''\n",
    "    for i in xrange(M.shape[0]):\n",
    "        r += un_one_hot(M[i])\n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Batch(object):\n",
    "    def __init__(self,words,words_pl,batch_size):\n",
    "        self.words = words\n",
    "        self.words_pl = words_pl\n",
    "        self.batch_size = batch_size\n",
    "        self.size = len(words)\n",
    "        self.segment_size = self.size/batch_size\n",
    "        self.cursors = [b*self.segment_size for b in range(batch_size)]\n",
    "        #self.batch = np.ndarray(self.batch_size)\n",
    "    def nextBatch(self,reverse = True):\n",
    "        if reverse:\n",
    "            x = np.array([vectorizeWord(pad_in(words[c][::-1])) for c in self.cursors])\n",
    "        else:\n",
    "            x = np.array([vectorizeWord(pad_in(words[c])) for c in self.cursors])\n",
    "        y = np.array([vectorizeWord(pad_out(words_pl[c])) for c in self.cursors])\n",
    "        self.cursors = [(c+1)%self.size for c in self.cursors]\n",
    "        return x,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep LSTM\n",
    "\n",
    "https://arxiv.org/pdf/1409.2329.pdf\n",
    "\n",
    "<img src=\"OtherLSTM.png\">  <img src=\"stacked_LSTM.png\", width = \"25%\", height = \"25%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a1 = tf.constant([[1,2],[3,4]])\n",
    "b1 = tf.slice(a1,[0,0],[2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [3]], dtype=int32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess2 = tf.Session()\n",
    "sess2.run(b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11,)\n",
      "(11, 14)\n"
     ]
    }
   ],
   "source": [
    "#NOTE: the +1 in max_in+1 and max_out+1 happens because the end token is needed\n",
    "\n",
    "num_nodes = 30\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    #input sequence\n",
    "    input_sequence = list()\n",
    "    for i in range(max_in+1):\n",
    "        input_sequence.append(tf.placeholder(tf.float32,shape=(batch_size,alphabet_size)))\n",
    "    \n",
    "    #target sequence\n",
    "    target_sequence = list()\n",
    "    for i in range(max_out+1):\n",
    "        target_sequence.append(tf.placeholder(tf.float32,shape=(batch_size,alphabet_size)))\n",
    "        \n",
    "    \n",
    "    #the previous state that gets fed into the cell\n",
    "    state_0 = tf.constant(0.0,dtype=tf.float32,shape=[batch_size,num_nodes])\n",
    "    hidden_0 = tf.constant(0.0,dtype=tf.float32,shape=[batch_size,num_nodes])\n",
    "    #for validation inference\n",
    "    state_0v = tf.constant(0.0,dtype=tf.float32,shape=[1,num_nodes])\n",
    "    hidden_0v = tf.constant(0.0,dtype=tf.float32,shape=[1,num_nodes])\n",
    "    \n",
    "    def create_LSTM_Variables(num_nodes,Name,is_input=False,is_second=False):\n",
    "        if is_input:\n",
    "            fx = tf.Variable(tf.truncated_normal([num_nodes+alphabet_size, num_nodes], -0.08, 0.08),name=Name+'fx')\n",
    "            ix = tf.Variable(tf.truncated_normal([num_nodes+alphabet_size, num_nodes], -0.08, 0.08),name=Name+'ix')\n",
    "            cx = tf.Variable(tf.truncated_normal([num_nodes+alphabet_size, num_nodes], -0.08, 0.08),name=Name+'cx')\n",
    "            ox = tf.Variable(tf.truncated_normal([num_nodes+alphabet_size, num_nodes], -0.08, 0.08),name=Name+'ox')\n",
    "        elif is_second:\n",
    "            fx = tf.Variable(tf.truncated_normal([3*num_nodes, num_nodes], -0.08, 0.08),name=Name+'fx')\n",
    "            ix = tf.Variable(tf.truncated_normal([3*num_nodes, num_nodes], -0.08, 0.08),name=Name+'ix')\n",
    "            cx = tf.Variable(tf.truncated_normal([3*num_nodes, num_nodes], -0.08, 0.08),name=Name+'cx')\n",
    "            ox = tf.Variable(tf.truncated_normal([3*num_nodes, num_nodes], -0.08, 0.08),name=Name+'ox')\n",
    "        else:\n",
    "            fx = tf.Variable(tf.truncated_normal([2*num_nodes, num_nodes], -0.08, 0.08),name=Name+'fx')\n",
    "            ix = tf.Variable(tf.truncated_normal([2*num_nodes, num_nodes], -0.08, 0.08),name=Name+'ix')\n",
    "            cx = tf.Variable(tf.truncated_normal([2*num_nodes, num_nodes], -0.08, 0.08),name=Name+'cx')\n",
    "            ox = tf.Variable(tf.truncated_normal([2*num_nodes, num_nodes], -0.08, 0.08),name=Name+'ox')\n",
    "        fb = tf.Variable(tf.zeros([1, num_nodes]),name=Name+'fb')\n",
    "        ib = tf.Variable(tf.zeros([1, num_nodes]),name=Name+'ib')\n",
    "        cb = tf.Variable(tf.zeros([1, num_nodes]),name=Name+'cb')\n",
    "        ob = tf.Variable(tf.zeros([1, num_nodes]),name=Name+'ob')\n",
    "        return[[fx,ix,cx,ox],[fb,ib,cb,ob]]\n",
    "    \n",
    "    e1_var = create_LSTM_Variables(num_nodes,'e1',is_input = True)\n",
    "    e2_var = create_LSTM_Variables(num_nodes,'e2')\n",
    "    e3_var = create_LSTM_Variables(num_nodes,'e3')\n",
    "    \n",
    "    d1_var = create_LSTM_Variables(num_nodes,'d1',is_input = True)\n",
    "    d2_var = create_LSTM_Variables(num_nodes,'d2',is_second = True)\n",
    "    d3_var = create_LSTM_Variables(num_nodes,'d3')\n",
    "    \n",
    "    #softmax\n",
    "    W_softmax = tf.Variable(tf.truncated_normal([num_nodes,alphabet_size],-0.08,0.08))\n",
    "    b_softmax = tf.Variable(tf.zeros([1,alphabet_size]))\n",
    "    \n",
    "    #model\n",
    "    #hl is the previous hiddent layer from current time step but previous  layer\n",
    "    #ht is the previous hidden layer from the current layer but previous timestep\n",
    "    #state is the previous state from the same layer but previous timestep\n",
    "    def LSTM(hl,ht,state,varrs):\n",
    "        #get variables out\n",
    "        x,b=varrs[0],varrs[1]\n",
    "        fx,ix,cx,ox = x[0],x[1],x[2],x[3]\n",
    "        fb,ib,cb,ob = b[0],b[1],b[1],b[3]\n",
    "        \n",
    "        #computations\n",
    "        input_chan = tf.concat([hl,ht],1)\n",
    "        forget_gate = tf.sigmoid(tf.matmul(input_chan,fx)+fb)\n",
    "        insert_gate = tf.sigmoid(tf.matmul(input_chan,ix)+ib)\n",
    "        output_gate = tf.sigmoid(tf.matmul(input_chan,ox)+ob)\n",
    "        candidate = tf.tanh(tf.matmul(input_chan,cx)+cb)\n",
    "        state = forget_gate * state + insert_gate * candidate\n",
    "        h = output_gate * tf.tanh(state)\n",
    "        return h, state\n",
    "    \n",
    "    def attention(h,d,encoder_size,decoder_size,attention_size=27,reuse=True):\n",
    "        \"\"\"\n",
    "        h : encoder states each element is [N,encoder_size]. array is length encoder_length\n",
    "        d : decoding query [N,decoder_size]\n",
    "        \n",
    "        Returns\n",
    "        new query d_prime [N,encoder_size]\n",
    "        an attention vector a [encoder_length]\n",
    "        \"\"\"\n",
    "        with tf.variable_scope('attention',reuse=reuse):\n",
    "            W_1=tf.get_variable('W_1',shape=[encoder_size,attention_size],initializer=tf.random_normal_initializer())\n",
    "            W_2=tf.get_variable('W_2',shape=[decoder_size,attention_size],initializer=tf.random_normal_initializer())\n",
    "            v = tf.get_variable('v',shape=[attention_size,1])\n",
    "        \n",
    "        u = []\n",
    "        for h_i in h:\n",
    "            u_i = tf.matmul(tf.tanh(tf.matmul(h_i,W_1)+tf.matmul(d,W_2)),v)\n",
    "            u.append(u_i)\n",
    "        \n",
    "        u=tf.concat(u,axis=1) #[N,encoder_length]\n",
    "        a = tf.nn.softmax(u)\n",
    "        d_prime = tf.reduce_sum(tf.expand_dims(a,axis=1) * tf.reshape(tf.concat(h,1),\n",
    "                                            (-1,encoder_size,len(h))),axis=2)\n",
    "        \n",
    "        return d_prime,a[0,:]\n",
    "        \n",
    "    \n",
    "    def model(input_sequence,train = True):\n",
    "        #Encode sequence\n",
    "        memory = list()\n",
    "        for i in range(max_in+1):\n",
    "            if i == 0:\n",
    "                if train:\n",
    "                    state1,h1 = state_0,hidden_0\n",
    "                    state2,h2 = state_0,hidden_0\n",
    "                    state3,h3 = state_0,hidden_0\n",
    "                else:\n",
    "                    state1,h1 = state_0v,hidden_0v\n",
    "                    state2,h2 = state_0v,hidden_0v\n",
    "                    state3,h3 = state_0v,hidden_0v\n",
    "\n",
    "            h1,state1 = LSTM(h1,input_sequence[i],state1,e1_var) #layer 1\n",
    "            h2,state2 = LSTM(h2,h1,state2,e2_var) #layer 2\n",
    "            h3,state3 = LSTM(h3,h2,state3,e3_var) #layer 3\n",
    "            memory.append(h3) #add output as to the memory for attention\n",
    "\n",
    "#         memory2=tf.concat(memory,1)\n",
    "#         #print(memory2.get_shape())\n",
    "#         #print(tf.reshape(memory2,(batch_size,num_nodes,-1)).shape)\n",
    "        \n",
    "        #Decode sequence\n",
    "        attention_values = list()\n",
    "        logits_list = list()\n",
    "        for i in range(max_out+1):\n",
    "            if i == 0:\n",
    "                h1,state1 = LSTM(h1,input_sequence[-1],state1,d1_var) #layer 1\n",
    "                if train:\n",
    "                    d_prime,a = attention(h=memory,d=h1,encoder_size=num_nodes,decoder_size=num_nodes,reuse=False)\n",
    "                else:\n",
    "                    d_prime,a = attention(h=memory,d=h1,encoder_size=num_nodes,decoder_size=num_nodes,reuse=True)\n",
    "\n",
    "            else:\n",
    "                h1,state1 = LSTM(h1,tf.nn.softmax(logit),state1,d1_var) #layer 1\n",
    "                d_prime,a = attention(h=memory,d=h1,encoder_size=num_nodes,decoder_size=num_nodes)\n",
    "            h2,state2 = LSTM(h2,tf.concat([d_prime,h1],axis=1),state2,d2_var) #layer 2\n",
    "            h3,state3 = LSTM(h3,h2,state3,d3_var) #layer 3\n",
    "\n",
    "            logit =tf.matmul(h3,W_softmax)+b_softmax\n",
    "            logits_list.append(logit)\n",
    "            attention_values.append(a)\n",
    "\n",
    "        logits = tf.concat(logits_list,0)\n",
    "        print(attention_values[0].shape)\n",
    "        attention_values=tf.transpose(tf.stack(attention_values,0))\n",
    "        print(attention_values.shape)\n",
    "        return logits,attention_values\n",
    "    \n",
    "    #train\n",
    "    logits_train,attention_values = model(input_sequence)\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits_train,labels=tf.concat(target_sequence,0)))\n",
    "    opt = tf.train.AdamOptimizer(learning_rate=1e-3).minimize(loss)\n",
    "    \n",
    "    #inference train\n",
    "    pred = tf.nn.softmax(logits_train)\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "        \n",
    "    init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session(graph = g)\n",
    "sess.run(init)\n",
    "b = Batch(words,words_pl,batch_size)\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# saver.restore(sess,os.getcwd()+'/model3_attention.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/5001 [00:00<08:34,  9.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.302704\n",
      "Input:           ~~~~gullit\n",
      "Output:          ullitgay~~~~~\n",
      "Correct Output:  ullitgay~~~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 103/5001 [00:08<06:43, 12.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.182563\n",
      "Input:           ~~~~eactor\n",
      "Output:          eactorway~~~~\n",
      "Correct Output:  eactorway~~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 203/5001 [00:16<06:30, 12.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.185674\n",
      "Input:           ~~~~~laide\n",
      "Output:          aidelay~~~~~~\n",
      "Correct Output:  aidelay~~~~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 303/5001 [00:24<06:20, 12.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.19154\n",
      "Input:           ~bananaman\n",
      "Output:          ananmmanbay~~\n",
      "Correct Output:  ananamanbay~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 403/5001 [00:32<06:09, 12.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.380778\n",
      "Input:           ~~~~~dimps\n",
      "Output:          impsday~~~~~~\n",
      "Correct Output:  impsday~~~~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 503/5001 [00:40<06:00, 12.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.259007\n",
      "Input:           ~sadlamulk\n",
      "Output:          adlamumysay~~\n",
      "Correct Output:  adlamulksay~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 603/5001 [00:48<05:51, 12.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.174261\n",
      "Input:           ~~~~~~neal\n",
      "Output:          ealnay~~~~~~~\n",
      "Correct Output:  ealnay~~~~~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 702/5001 [00:56<05:45, 12.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.192062\n",
      "Input:           ~~~relearn\n",
      "Output:          elearnray~~~~\n",
      "Correct Output:  elearnray~~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 802/5001 [01:04<05:39, 12.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.163568\n",
      "Input:           ~~~lecanii\n",
      "Output:          ecaniilay~~~~\n",
      "Correct Output:  ecaniilay~~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 902/5001 [01:12<05:30, 12.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.214975\n",
      "Input:           ~~~~~bobak\n",
      "Output:          obakbay~~~~~~\n",
      "Correct Output:  obakbay~~~~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1002/5001 [01:21<05:23, 12.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.276154\n",
      "Input:           ~~~~schack\n",
      "Output:          ackschay~~~~~\n",
      "Correct Output:  ackschay~~~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 1102/5001 [01:28<05:14, 12.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.146928\n",
      "Input:           ~~~~~~rels\n",
      "Output:          elsray~~~~~~~\n",
      "Correct Output:  elsray~~~~~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 1202/5001 [01:36<05:06, 12.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.217687\n",
      "Input:           ~proffered\n",
      "Output:          offeredpray~~\n",
      "Correct Output:  offeredpray~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 1302/5001 [01:45<04:58, 12.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.169613\n",
      "Input:           ~pombalina\n",
      "Output:          ombalinapay~~\n",
      "Correct Output:  ombalinapay~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 1402/5001 [01:53<04:50, 12.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.228216\n",
      "Input:           ~~furihime\n",
      "Output:          uribimefay~~~\n",
      "Correct Output:  urihimefay~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 1502/5001 [02:02<04:45, 12.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.197745\n",
      "Input:           ~~bulafiji\n",
      "Output:          ulabomibay~~~\n",
      "Correct Output:  ulafijibay~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 1602/5001 [02:10<04:36, 12.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.151861\n",
      "Input:           ~manouvres\n",
      "Output:          anouvresmay~~\n",
      "Correct Output:  anouvresmay~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 1702/5001 [02:18<04:27, 12.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.216108\n",
      "Input:           ~~suburban\n",
      "Output:          uburhansay~~~\n",
      "Correct Output:  uburbansay~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 1802/5001 [02:26<04:19, 12.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.168616\n",
      "Input:           ~biollante\n",
      "Output:          iollantebay~~\n",
      "Correct Output:  iollantebay~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 1902/5001 [02:34<04:11, 12.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.177692\n",
      "Input:           ~aryabhata\n",
      "Output:          aryahhataway~\n",
      "Correct Output:  aryabhataway~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2002/5001 [02:42<04:02, 12.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.153501\n",
      "Input:           ~maroilles\n",
      "Output:          aroillesmay~~\n",
      "Correct Output:  aroillesmay~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 2102/5001 [02:50<03:54, 12.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.122396\n",
      "Input:           ~marrubium\n",
      "Output:          arrubiummay~~\n",
      "Correct Output:  arrubiummay~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 2202/5001 [02:58<03:47, 12.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.220635\n",
      "Input:           ~~~newnham\n",
      "Output:          ewnhamday~~~~\n",
      "Correct Output:  ewnhamnay~~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 2302/5001 [03:07<03:39, 12.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.163878\n",
      "Input:           ~~~~aemvli\n",
      "Output:          aemmliway~~~~\n",
      "Correct Output:  aemvliway~~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 2402/5001 [03:14<03:30, 12.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.207399\n",
      "Input:           ~~~~~~~ped\n",
      "Output:          edpay~~~~~~~~\n",
      "Correct Output:  edpay~~~~~~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2502/5001 [03:22<03:22, 12.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.177993\n",
      "Input:           ~~~lepanto\n",
      "Output:          epantolay~~~~\n",
      "Correct Output:  epantolay~~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 2602/5001 [03:30<03:14, 12.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.11365\n",
      "Input:           ~~~~~astan\n",
      "Output:          astanway~~~~~\n",
      "Correct Output:  astanway~~~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 2702/5001 [03:38<03:05, 12.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.155526\n",
      "Input:           ~~thomists\n",
      "Output:          omiststhay~~~\n",
      "Correct Output:  omiststhay~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 2802/5001 [03:46<02:57, 12.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.163786\n",
      "Input:           ~~~crudely\n",
      "Output:          udelycray~~~~\n",
      "Correct Output:  udelycray~~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 2902/5001 [03:54<02:49, 12.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.169864\n",
      "Input:           ~~gunperry\n",
      "Output:          unperrygay~~~\n",
      "Correct Output:  unperrygay~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3002/5001 [04:03<02:42, 12.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.225695\n",
      "Input:           procumbent\n",
      "Output:          ocumbentpray~\n",
      "Correct Output:  ocumbentpray~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 3102/5001 [04:11<02:33, 12.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.141438\n",
      "Input:           ~~~~kupier\n",
      "Output:          upierkay~~~~~\n",
      "Correct Output:  upierkay~~~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 3202/5001 [04:19<02:25, 12.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.112426\n",
      "Input:           cybernetic\n",
      "Output:          ernetichyyay~\n",
      "Correct Output:  erneticcybay~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 3302/5001 [04:26<02:17, 12.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.214723\n",
      "Input:           ~~~~~fugac\n",
      "Output:          ugacfay~~~~~~\n",
      "Correct Output:  ugacfay~~~~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 3402/5001 [04:34<02:09, 12.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.13214\n",
      "Input:           ~~weaponry\n",
      "Output:          eaponryway~~~\n",
      "Correct Output:  eaponryway~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 3502/5001 [04:42<02:01, 12.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.155652\n",
      "Input:           ~compilers\n",
      "Output:          ompilerscay~~\n",
      "Correct Output:  ompilerscay~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 3602/5001 [04:50<01:52, 12.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.21696\n",
      "Input:           ~~~~~gaafu\n",
      "Output:          aafugay~~~~~~\n",
      "Correct Output:  aafugay~~~~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 3702/5001 [04:58<01:44, 12.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.175608\n",
      "Input:           ~arborwiki\n",
      "Output:          arborligiway~\n",
      "Correct Output:  arborwikiway~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 3803/5001 [05:07<01:36, 12.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.133983\n",
      "Input:           ~~pontiana\n",
      "Output:          ontianapay~~~\n",
      "Correct Output:  ontianapay~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 3903/5001 [05:15<01:28, 12.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.136566\n",
      "Input:           ~~~~~~norr\n",
      "Output:          orrnay~~~~~~~\n",
      "Correct Output:  orrnay~~~~~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4003/5001 [05:23<01:20, 12.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.156118\n",
      "Input:           ~~teachers\n",
      "Output:          eacherstay~~~\n",
      "Correct Output:  eacherstay~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 4103/5001 [05:31<01:12, 12.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.1287\n",
      "Input:           ~~~~~~gifu\n",
      "Output:          ifugay~~~~~~~\n",
      "Correct Output:  ifugay~~~~~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 4203/5001 [05:38<01:04, 12.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.14658\n",
      "Input:           ~~~pachman\n",
      "Output:          achmanpay~~~~\n",
      "Correct Output:  achmanpay~~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 4303/5001 [05:46<00:56, 12.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.148113\n",
      "Input:           ~~~~~~baky\n",
      "Output:          akybay~~~~~~~\n",
      "Correct Output:  akybay~~~~~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 4403/5001 [05:54<00:48, 12.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.102193\n",
      "Input:           ~~~~~~lurd\n",
      "Output:          urdlay~~~~~~~\n",
      "Correct Output:  urdlay~~~~~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 4503/5001 [06:03<00:40, 12.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.258336\n",
      "Input:           ~~~~slumps\n",
      "Output:          umpsslay~~~~~\n",
      "Correct Output:  umpsslay~~~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 4603/5001 [06:11<00:32, 12.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.2272\n",
      "Input:           ~~~~lastra\n",
      "Output:          astralay~~~~~\n",
      "Correct Output:  astralay~~~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 4703/5001 [06:19<00:24, 12.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.292158\n",
      "Input:           ~~~armesto\n",
      "Output:          armestoway~~~\n",
      "Correct Output:  armestoway~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 4801/5001 [06:26<00:16, 12.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.102245\n",
      "Input:           ~~~~~~~vwo\n",
      "Output:          ovmay~~~~~~~~\n",
      "Correct Output:  ovway~~~~~~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 4903/5001 [06:35<00:07, 12.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.121481\n",
      "Input:           ~~bayqarah\n",
      "Output:          aykarahbay~~~\n",
      "Correct Output:  ayqarahbay~~~\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5001/5001 [06:42<00:00, 12.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.168917\n",
      "Input:           unmanifest\n",
      "Output:          unmanifetsway\n",
      "Correct Output:  unmanifestway\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_steps = 5001\n",
    "# num_steps = 11\n",
    "for s in tqdm(range(num_steps)):\n",
    "    fd = {}\n",
    "    x,y = b.nextBatch(reverse=False)\n",
    "    for i in range(len(x[0,:,0])):\n",
    "        fd[input_sequence[i]] = x[:,i,:]\n",
    "    for i in range(len(y[0,:,0])):\n",
    "        fd[target_sequence[i]] = y[:,i,:]\n",
    "    \n",
    "    l,_ = sess.run([loss,opt],feed_dict = fd)\n",
    "    losses.append(l)\n",
    "    if s % 100 == 0:\n",
    "        translated = sess.run([pred],feed_dict=fd)[0]\n",
    "        #onlt check the first word\n",
    "        fw_o = np.ndarray((max_out,alphabet_size))\n",
    "        for i in range(max_out):\n",
    "            fw_o[i]=translated[i*batch_size]\n",
    "    \n",
    "        print 'loss: ',l\n",
    "        print 'Input:          ',unvectorizeWord(x[0])#[::-1]\n",
    "        print 'Output:         ',unvectorizeWord(fw_o)\n",
    "        print 'Correct Output: ',unvectorizeWord(y[0])\n",
    "        print ' '\n",
    "#save_path = saver.save(sess,os.getcwd()+'/model3_attention.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x145be5a10>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAAEGCAYAAACToKXdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrLdk7Y4HAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x145b4ecd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "attention_matrix,translated = sess.run([attention_values,pred],feed_dict=fd)\n",
    "fw_o = np.ndarray((max_out,alphabet_size))\n",
    "for i in range(max_out):\n",
    "    fw_o[i]=translated[i*batch_size]\n",
    "translated_word = unvectorizeWord(fw_o)\n",
    "input_word = unvectorizeWord(x[0])\n",
    "plt.imshow(attention_matrix)\n",
    "plt.colorbar()\n",
    "plt.xticks(np.arange(len(translated_word)),translated_word)\n",
    "plt.yticks(np.arange(len(input_word)),input_word)\n",
    "plt.ylabel('Encoding Step')\n",
    "plt.xlabel('Decoding Step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'~~~~~~pary'"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x146a8f550>]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD9CAYAAABHnDf0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1459a9ad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11,)\n",
      "(11, 14)\n"
     ]
    }
   ],
   "source": [
    "with g.as_default():\n",
    "    val_sequence = list()\n",
    "    for i in range(max_in+1):\n",
    "        val_sequence.append(tf.placeholder(tf.float32,shape=(1,alphabet_size)))\n",
    "    logits_val,_ = model(val_sequence,train=False)\n",
    "    pred_val = tf.nn.softmax(logits_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:           abaya\n",
      "Output:          ayabaway~~~~~\n",
      " \n",
      "Input:           bardolatry\n",
      "Output:          aludrilkcray~\n",
      " \n",
      "Input:           blatherski\n",
      "Output:          issretrallway\n",
      " \n",
      "Input:           couthy\n",
      "Output:          uochyyay~~~~~\n",
      " \n",
      "Input:           deterge\n",
      "Output:          egretedway~~~\n",
      " \n",
      "Input:           eyewater\n",
      "Output:          etaweyeray~~~\n",
      " \n",
      "Input:           saudade\n",
      "Output:          edadeasway~~~\n",
      " \n",
      "Input:           tokoloshe\n",
      "Output:          ehsologotway~\n",
      " \n",
      "Input:           wittol\n",
      "Output:          ottiwlay~~~~~\n",
      " \n",
      "Input:           vomitous\n",
      "Output:          uotimovsay~~~\n",
      " \n",
      "Input:           waitron\n",
      "Output:          ortiawnay~~~~\n",
      " \n"
     ]
    }
   ],
   "source": [
    "#validation\n",
    "for s in range(len(uncommon)):\n",
    "    inputs = vectorizeWord(pad_in(uncommon[s][::-1]))\n",
    "    \n",
    "    fd = {}\n",
    "    for i in range(len(inputs)):\n",
    "        fd[val_sequence[i]] = np.expand_dims(inputs[i],0)\n",
    "    \n",
    "    translated = sess.run([pred_val],feed_dict=fd)[0]\n",
    "    print 'Input:          ',uncommon[s]\n",
    "    print 'Output:         ',unvectorizeWord(translated)\n",
    "    print ' '"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Get Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_params = sess.run([e1_var,e2_var,e3_var,d1_var,d2_var,d3_var,W_softmax,b_softmax])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(model_params,open('params_attention.p','w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
